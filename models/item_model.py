import copy
from datetime import datetime
import requests
import re
from bs4 import BeautifulSoup

invisible_char = "\u00A0"

class Item:
    default_media = {
        "photo": [],
        "video": [],
        "audio": [],
        "document": [],
        "voice": [],
        "video_note": [],
        "location": [],
        "contact": [],
        "sticker": [],
    }

    def __init__(self, text: str, title=None, media: dict = None, date_created=None, date_modified=None):
        self.title = title
        self.text = text
        if not media:
            self.media = copy.deepcopy(self.default_media)
        else:
            self.media = media
        self.date_created = date_created or datetime.now()
        self.date_modified = date_modified or self.date_created

    def to_dict(self):
        return {
            "title": self.title,
            "text": self.text,
            "media": self.media,
            "date_created": self.date_created,
            "date_modified": self.date_modified
        }

    async def get_all_media_values(self):
        all_values = []
        for key, value in self.media.items():
            all_values.extend(value)
        return all_values

    async def get_title(self):
        title = self.title if self.title else ""
        need_added_chars = 70 - len(title)
        if need_added_chars > 0:
            for i in range(need_added_chars):
                title += ' '
            title += f"\n{invisible_char}"
        return title

    async def get_inline_title(self):
        return self.title if self.title and self.title != "" else (self.text.splitlines()[0] if self.text and self.text != "" else "")

    async def get_body(self):
        title = await self.get_title()
        return f"üìÑ <b>{title}</b>\n{self.text}"


    def get_short_parse_title(self):
        urls = re.findall(r'https?://[^\s]+', self.text)

        if not urls:
            words = self.text.split()
            short_title = " ".join(words[:3])
            if len(words) > 3:
                short_title = short_title + "..."
            return short_title

        for url in urls:
            print(url)
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π URL
        url = urls[0]

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ HTML-–∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        response = requests.get(url)
        html_code = response.text

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º BeautifulSoup –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML-–∫–æ–¥–∞
        soup = BeautifulSoup(html_code, 'html.parser')

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        try:
            short_title = soup.title.string
        except:
            words = self.text.split()
            short_title = " ".join(words[:3])
            if len(words) > 3:
                short_title = short_title + "..."
            return short_title

        return short_title

    def select_search_text(self, search_text: str, left_teg: str = '<b><i><u>', right_teg: str = '</u></i></b>'):
        self.title = get_selected_search_text(self.title, search_text, left_teg, right_teg)
        self.text = get_selected_search_text(self.text, search_text, left_teg, right_teg)

    def __str__(self):
        return f"{self.title} ({self.date_created.strftime('%Y-%m-%d %H:%M:%S')})"


def get_selected_search_text(text: str, search_text: str, left_teg: str = '<b><i><u>', right_teg: str = '</u></i></b>'):
    # –ò—â–µ–º –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è search_text –≤ —Ç–µ–∫—Å—Ç–µ
    if text:
        start_index = text.lower().find(search_text.lower())
    else:
        return text

    while start_index != -1:
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–¥—Å—Ç—Ä–æ–∫—É –¥–æ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è
        prefix = text[:start_index]

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–¥—Å—Ç—Ä–æ–∫—É —Å —Ç–µ–≥–∞–º–∏ <u> </u>
        underlined_text = f'{left_teg}{text[start_index: start_index + len(search_text)]}{right_teg}'

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–¥—Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è
        suffix = text[start_index + len(search_text):]

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç—Ä–∏ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏
        text = f"{prefix}{underlined_text}{suffix}"

        if text:
            #–ò—â–µ–º —Å–ª–µ–¥—É—é—â–µ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ search_text, –∏—Å–∫–ª—é—á–∞—è —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            start_index = text.lower().find(search_text.lower(), start_index + len(underlined_text))
        else:
            start_index = -1

    return text
